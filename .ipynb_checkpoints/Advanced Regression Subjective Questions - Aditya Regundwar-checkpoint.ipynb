{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfdfe28",
   "metadata": {},
   "source": [
    "# <font color=ORANGE>Assignment-based Subjective Questions</FONT>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97c36c",
   "metadata": {},
   "source": [
    "## <font color=green> Question 1 : What is the optimal value of alpha for ridge and lasso regression? What will be the changes in the model if you choose double the value of alpha for both ridge and lasso? What will be the most important predictor variables after the change is implemented ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5572f",
   "metadata": {},
   "source": [
    "1. The ***optimal value of lambda*** we got in case of Ridge and Lasso is :\n",
    "    - Ridge - 2.0\n",
    "    - Lasso - 0.0001\n",
    "    \n",
    "    \n",
    "2. The changes in the model if we choose to double the value of alpha for both ridge and lasso are:\n",
    "\n",
    "    - When we double the alpha value ***in case of ridge there is a slight increase in the mean squared error*** whereas the ***R2 value of train and test remains almost same***\n",
    "    - When we double the alpha value in case of lasso there is a ***slight increase in the mean squared error***, the ***R2 value of train slightly decreases whereas there is a huge fall in the r2 value of test thus making the model and prediction worse***\n",
    "    - ***It also penalizes the model even more and a greater number of coefficients of a variable shrink towards zero.***\n",
    "\n",
    "\n",
    "3. The most important predictor variables after the changes are implemented are:\n",
    "\n",
    "    - For Ridge :\n",
    "        1. Total_sqr_footage        0.121636\n",
    "        2. OverallQual              0.111001\n",
    "        3. GrLivArea                0.103918\n",
    "        4. Neighborhood_StoneBr     0.080427\n",
    "        5. OverallCond              0.071092\n",
    "        6. TotalBsmtSF              0.057602\n",
    "        7. LotArea                  0.052836\n",
    "        8. YearBuilt                0.047895\n",
    "        9. Neighborhood_Crawfor     0.046547\n",
    "        10. Fireplaces              0.041275\n",
    "\n",
    "    - For Lasso:\n",
    "        1. Total_sqr_footage        0.185432\n",
    "        2. OverallQual              0.172690\n",
    "        3. YearBuilt                0.119993\n",
    "        4. GrLivArea                0.105463\n",
    "        5. Neighborhood_StoneBr     0.093874\n",
    "        6. OverallCond              0.089137\n",
    "        7. LotArea                  0.054712\n",
    "        8. Neighborhood_Crawfor     0.053322\n",
    "        9. Neighborhood_NridgHt     0.047466\n",
    "        10. GarageCars               0.044402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a9557",
   "metadata": {},
   "source": [
    "## <font color=green> Question 2 : You have determined the optimal value of lambda for ridge and lasso regression during the assignment. Now, which one will you choose to apply and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885973c",
   "metadata": {},
   "source": [
    "- The optimal value of LAMBDA we got in case of Ridge and Lasso is:\n",
    "    - Ridge - 2.0\n",
    "    - Lasso - 0.0001\n",
    "\n",
    "\n",
    "- The r2 value we got in case of Ridge and Lasso is:\n",
    "    - Ridge - Train = 0.930, Test = 0.896, difference – 0.046\n",
    "    - Lasso - Train = 0.927, Test = 0.902, difference – 0.025\n",
    "\n",
    "\n",
    "- The Mean Squared error in case of Ridge and Lasso is:\n",
    "    - Ridge - 0.00297\n",
    "    - Lasso - 0.00280\n",
    "\n",
    "\n",
    "- We can clearly observe that the Mean Squared Error of Lasso is slightly lower than that of Ridge\n",
    "- Also difference of r2 between train and test is less in lasso as compared to ridge.\n",
    "- Since Lasso helps in feature reduction and also is giving better result means we can ignore some varibles, so we prefer lasso over ridge here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4463a",
   "metadata": {},
   "source": [
    "## <font color=green> Question 3 : After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971b403",
   "metadata": {},
   "source": [
    "- We dropped the top 5 most important predictor variables in the lasso model and again created again model and got the below five most important predictor variables:\n",
    "\n",
    "\n",
    "    1. TotalBsmtSF         0.322970\n",
    "    2. TotRmsAbvGrd        0.126251\n",
    "    3. OverallCond         0.094274\n",
    "    4. Total_Bathrooms     0.086846\n",
    "    5. LotArea             0.067737\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8dd486",
   "metadata": {},
   "source": [
    "## <font color=green> Question 4 : How can you make sure that a model is robust and generalisable? What are the implications of the same for the accuracy of the model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e097b7",
   "metadata": {},
   "source": [
    "- The model is expected to be as simple as possible and simpler models are considered as more ‘generic’, though its accuracy will be decreased but it will be more robust.\n",
    "\n",
    "\n",
    "-  This can be understood from the Bias-Variance trade-off. The simpler the model the more the bias but less variance becoming generalizable. Whereas the complex model will have high variance and low bias.\n",
    "\n",
    "\n",
    "- Sometimes underfitting and overfitting are the problems associated with the model. Hence, it is important to have balance in Bias and Variance to avoid such problems. This is possible with “Regularization”.\n",
    "\n",
    "\n",
    "- Regularization helps in managing the model complexity by essentially shrinking the coefficients towards zero. This avoids the model becoming too complex, thus reducing the risk of overfitting.\n",
    "\n",
    "\n",
    "- Regularization method should be used to keep the model optimum simpler. It penalizes the model if it becomes more complex.\n",
    "\n",
    "\n",
    "- Regularization method helps to achieve the Bias-Variance trade off. It compromises by increasing bias to a optimum position where Total Error is minimum.\n",
    "\n",
    "\n",
    "- This point also known as Optimum Model Complexity where Model is sufficient simpler to be generalisable and also complex enough to be robust.\n",
    "\n",
    "\n",
    "- Making a model simple lead to Bias-Variance trade off. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
